'''Downloads and generates the data needed for semantic role labeling.'''

import html.parser
import re
import urllib.request
from pprint import pprint

frame_id_re = re.compile('va:[0-9]{4}f')

class VerbAtlasFramesParser(html.parser.HTMLParser):

	def __init__(self):
		super().__init__()
		self.get_data = False
		self.frames = []

	def handle_starttag(self, tag, attrs):
		if tag != 'a': return
		for attribute, value in attrs:
			if attribute == 'id' and frame_id_re.match(value):
				self.get_data = True

	def handle_endtag(self, tag):
		self.get_data = False

	def handle_data(self, data):
		if not self.get_data: return
		data = data.strip()
		if not data: return
		data = data.upper()
		data = data.replace(' â€¢ ', '_')
		data = data.replace(' ', '-')
		self.frames.append(data)

class VerbAtlasSemanticRolesParser(html.parser.HTMLParser):

	def __init__(self):
		super().__init__()
		self.get_data = False
		self.semantic_roles = []

	def handle_starttag(self, tag, attrs):
		if tag != 'p': return
		if attrs != [('class', 'sem')]: return
		self.get_data = True

	def handle_endtag(self, tag):
		self.get_data = False

	def handle_data(self, data):
		if not self.get_data: return
		data = data.replace('_', '-')
		self.semantic_roles.append(data)

class UniversalPOSTagsParser(html.parser.HTMLParser):

	def __init__(self):
		super().__init__()
		self.is_indide_li = False
		self.get_data = False
		self.pos_tags = []

	def handle_starttag(self, tag, attrs):
		if tag != 'li' and tag != 'a': return
		if tag == 'li':
			self.is_indide_li = True
			return
		if self.is_indide_li and tag == 'a':
			self.get_data = True
			return
		assert tag == 'a' and not self.is_indide_li

	def handle_endtag(self, tag):
		if tag == 'li': self.is_indide_li = False
		self.get_data = False

	def handle_data(self, data):
		if not self.get_data: return
		self.pos_tags.append(data)

frames_parser = VerbAtlasFramesParser()
semantic_roles_parser = VerbAtlasSemanticRolesParser()
pos_tags_parser = UniversalPOSTagsParser()
arguments = [
	(frames_parser, 'https://verbatlas.org/frames'),
	(semantic_roles_parser, 'https://verbatlas.org/semantic'),
	(pos_tags_parser, 'https://universaldependencies.org/u/pos/')
]
for parser, url in arguments:
	with urllib.request.urlopen(url) as resp:
		for line in resp:
			parser.feed(line.decode('utf-8'))

# Why the fuck predicates with the W are not present?
frames_parser.frames.extend(
	['WAIT', 'WARN', 'WASH_CLEAN', 'WATCH_LOOK-OUT','WELCOME', 'WIN', 'WORK',
	'WORSEN', 'WRITE']
)

with open('stud/data.py', 'w') as f:
	print(f'# auto generated by {__file__}\n', file=f)
	print('semantic_roles = ', end='', file=f)
	pprint(semantic_roles_parser.semantic_roles, stream=f)
	print('', file=f)
	print('predicates = ', end='', file=f)
	pprint(frames_parser.frames, stream=f)
	print('', file=f)
	print('pos_tags = ', end='', file=f)
	pprint(pos_tags_parser.pos_tags, stream=f)
